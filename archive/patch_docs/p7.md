좋아. 되돌림 이슈 때문에 안전하게 **새 모듈로 3개 함수**를 추가하고, `report_generator.py`에서 그 함수를 **정확한 위치**에서 호출하도록 패치할게. 아래 그대로 반영하면 돼.

---

# 1) 새 파일 추가: `core/flow_ledger_v2.py`

(프로젝트 루트 기준, 기존 `header_registry/header_normalizer`가 import 가능한 **같은 패키지**에 두세요.)

```python
# core/flow_ledger_v2.py
# -*- coding: utf-8 -*-
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
import pandas as pd

from header_registry import HVDC_HEADER_REGISTRY
from header_normalizer import HeaderNormalizer

# --- 정규화 기본 ---
_WAREHOUSE_KEYS: Tuple[str, ...] = (
    "dhl_wh","dsv_indoor","dsv_al_markaz","dsv_outdoor",
    "dsv_mzp","jdn_mzd","hauler_indoor","aaa_storage","mosb",
)
SITES = {"AGI","DAS","MIR","SHU"}

def _warehouse_labels() -> List[str]:
    reg = HVDC_HEADER_REGISTRY
    return [reg.get_definition(k).description for k in _WAREHOUSE_KEYS]

WAREHOUSES = set(_warehouse_labels())

def _canon_map() -> Dict[str, str]:
    n = HeaderNormalizer()
    m: Dict[str,str] = {}
    for lab in (WAREHOUSES | SITES):
        m[n.normalize(lab)] = lab
    return m

def _canon(v: object, amap: Dict[str, str], n=HeaderNormalizer()) -> Optional[str]:
    if v is None or (isinstance(v, float) and pd.isna(v)): return None
    s = str(v).strip()
    return amap.get(n.normalize(s))

# --- 타임존/월 버킷 ---
DUBAI_TZ = "Asia/Dubai"

def _to_dubai_ym(ts: pd.Series) -> pd.Series:
    s = pd.to_datetime(ts, errors="coerce", utc=True)     # 파싱 실패/범위초과는 NaT 처리. :contentReference[oaicite:0]{index=0}
    s = s.dt.tz_convert(DUBAI_TZ).dt.tz_localize(None)    # tz-aware → 두바이로 변환 후 tz 제거. :contentReference[oaicite:1]{index=1}
    return s.dt.strftime("%Y-%m")

# --- 이벤트 모델 ---
@dataclass
class Event:
    case: str
    ym: str
    kind: str           # "IN" | "OUT"
    warehouse: str
    qty: int
    ts: pd.Timestamp
    src: Optional[str] = None
    dst: Optional[str] = None

# --- 동일시각 병합(sum 정책) ---
def _coalesce_same_timestamp(g: pd.DataFrame) -> List[Tuple[pd.Timestamp, List[str], int]]:
    out: List[Tuple[pd.Timestamp, List[str], int]] = []
    for ts, gg in g.groupby("ts"):
        whs = [r.loc for r in gg.sort_values(["stage_prio","wh_prio"]).itertuples() if r.loc in WAREHOUSES]
        qty = int(gg["qty"].sum())  # ← 동일 시각은 합산
        out.append((ts, whs, qty))
    return out

STAGE_PRIO = {"pre_arrival":0, "warehouse":1, "site":2, "shipping":3}
WH_PRIO = {
    "DSV Al Markaz": 10, "DSV Indoor": 20, "DSV Outdoor": 30, "AAA Storage": 40,
    "Hauler Indoor": 50, "DSV MZP": 60, "JDN MZD": 70, "MOSB": 80, "DHL WH": 90,
}

def _stage_of(loc: Optional[str]) -> str:
    if not loc: return "shipping"
    if loc in WAREHOUSES: return "warehouse"
    if loc in SITES:      return "site"
    lo = loc.lower()
    if ("pre" in lo and "arrival" in lo) or "eta" in lo or "etd" in lo:
        return "pre_arrival"
    return "shipping"

# --- ① 타임라인 → 전이 레저 ---
def build_flow_ledger(master_df: pd.DataFrame,
                      case_cols=("Case No","Case","Case_ID","Case_Number","case_no","case"),
                      qty_cols=("Pkg","pkg","Pkg_Quantity","pkg_quantity","quantity","qty")) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    상태 타임라인(가로형 날짜 열) → 전이 레저(입/출) 생성.
    반환:
      - ledger_df: Year_Month, Warehouse, Kind, Qty
      - edges_df : case, ts, src, dst, qty (이동 상세)
    """
    if master_df is None or master_df.empty:
        cols = ["Year_Month","Warehouse","Kind","Qty"]
        return pd.DataFrame(columns=cols), pd.DataFrame(columns=["case","ts","src","dst","qty"])

    df = master_df.copy()

    def _pick(cands):
        cc = {c.lower().replace(" ","_") for c in cands}
        for c in df.columns:
            if c.lower().replace(" ","_") in cc: return c
        return None

    col_case = _pick(case_cols) or "row_id"
    if col_case not in df.columns:
        df[col_case] = df.index

    col_qty = _pick(qty_cols)
    if not col_qty:
        col_qty = "__qty__"
        df[col_qty] = 1

    amap = _canon_map()

    # 가로형 상태/위치 날짜열만 melt (표준: pandas.melt) :contentReference[oaicite:2]{index=2}
    loc_cols = [c for c in df.columns if _canon(c, amap) in (WAREHOUSES | SITES)]
    long = df[[col_case, col_qty] + loc_cols].melt(
        id_vars=[col_case, col_qty], var_name="loc", value_name="ts"
    ).dropna(subset=["ts"]).copy()

    # 두바이 기준 타임존/월버킷 적용 (to_datetime → tz_convert) :contentReference[oaicite:3]{index=3}
    long["ts"] = pd.to_datetime(long["ts"], errors="coerce", utc=True)
    long = long.dropna(subset=["ts"])
    long["Year_Month"] = _to_dubai_ym(long["ts"])

    # 위치/정렬 키
    long["loc"] = long["loc"].map(lambda s: _canon(s, amap))
    long["stage"] = long["loc"].map(_stage_of)
    long["stage_prio"] = long["stage"].map(STAGE_PRIO)
    long["wh_prio"] = long["loc"].map(lambda s: WH_PRIO.get(s, 999))
    long["qty"] = long[col_qty].fillna(1).clip(lower=1).astype(int)

    long = long.sort_values([col_case, "ts", "stage_prio", "wh_prio"]).reset_index(drop=True)

    # 동일시각 병합(sum) + 창고 체인 전이
    events: List[Event] = []
    edges: List[Tuple[str, pd.Timestamp, Optional[str], Optional[str], int]] = []

    for case, g in long.groupby(col_case, sort=False):
        timeline: List[Tuple[pd.Timestamp, str, int]] = []
        for ts, wh_list, qty in _coalesce_same_timestamp(g):
            if not wh_list:
                first_row = g[g["ts"] == ts].iloc[0]
                timeline.append((ts, first_row.loc, qty))
                continue
            prev = None
            for wh in wh_list:
                if prev is None:
                    timeline.append((ts, wh, qty))
                else:
                    edges.append((str(case), ts, prev, wh, qty))
                prev = wh

        # 같은 시각·같은 위치는 1건으로 축약
        compact: List[Tuple[pd.Timestamp, str, int]] = []
        for ts, loc, qty in sorted(timeline, key=lambda x: (x[0], WH_PRIO.get(x[1], 999))):
            if compact and compact[-1][0] == ts and compact[-1][1] == loc:
                compact[-1] = (ts, loc, max(compact[-1][2], qty))
            else:
                compact.append((ts, loc, qty))

        # 전이 해석 → IN/OUT
        prev_loc: Optional[str] = None
        for ts, loc, qty in compact:
            ym = _to_dubai_ym(pd.Series([ts])).iloc[0]
            if prev_loc is None:
                if loc in WAREHOUSES:
                    events.append(Event(str(case), ym, "IN", loc, qty, ts, src=None, dst=loc))
            else:
                if prev_loc in WAREHOUSES and loc in WAREHOUSES and prev_loc != loc:
                    edges.append((str(case), ts, prev_loc, loc, qty))
                    events.append(Event(str(case), ym, "OUT", prev_loc, qty, ts, src=prev_loc, dst=loc))
                    events.append(Event(str(case), ym, "IN",  loc,      qty, ts, src=prev_loc, dst=loc))
                elif prev_loc in WAREHOUSES and loc in SITES:
                    events.append(Event(str(case), ym, "OUT", prev_loc, qty, ts, src=prev_loc, dst=loc))
                elif prev_loc not in WAREHOUSES and loc in WAREHOUSES:
                    events.append(Event(str(case), ym, "IN",  loc,      qty, ts, src=prev_loc, dst=loc))
            prev_loc = loc

    if not events:
        cols = ["Year_Month","Warehouse","Kind","Qty"]
        return pd.DataFrame(columns=cols), pd.DataFrame(columns=["case","ts","src","dst","qty"])

    ev = pd.DataFrame([e.__dict__ for e in events])
    ledger = (
        ev.groupby(["ym","warehouse","kind"], as_index=False)["qty"].sum()
          .rename(columns={"ym":"Year_Month","warehouse":"Warehouse","kind":"Kind","qty":"Qty"})
    )
    edges_df = pd.DataFrame(edges, columns=["case","ts","src","dst","qty"]).sort_values(["case","ts"])
    return ledger, edges_df

# --- ② 월별 입/출고 표 ---
def monthly_inout_table(ledger: pd.DataFrame, warehouses: Optional[List[str]] = None) -> pd.DataFrame:
    if ledger is None or ledger.empty:
        return pd.DataFrame(columns=["입고월"])
    warehouses = warehouses or _warehouse_labels()

    piv = (  # 피벗은 문서상 fill_value 지원. :contentReference[oaicite:4]{index=4}
        ledger.pivot_table(index="Year_Month", columns=["Warehouse","Kind"], values="Qty",
                           aggfunc="sum", fill_value=0)
              .sort_index()
    )
    out = pd.DataFrame({"입고월": piv.index})
    for w in warehouses:
        ins  = piv.get((w,"IN"),  pd.Series(0, index=piv.index))
        outs = piv.get((w,"OUT"), pd.Series(0, index=piv.index))
        out[f"입고_{w}"] = ins.astype(int).values
        out[f"출고_{w}"] = outs.astype(int).values
        out[f"누적_{w}"] = (ins - outs).cumsum().astype(int).values  # cumsum 표준. :contentReference[oaicite:5]{index=5}
    return out.reset_index(drop=True)

# --- ③ 검산 리포트 ---
def sanity_report(df_monthly: pd.DataFrame):
    bad = []
    for w in sorted({c.split("_",1)[1] for c in df_monthly.columns if c.startswith("입고_")}):
        s_in  = int(df_monthly[f"입고_{w}"].sum())
        s_out = int(df_monthly[f"출고_{w}"].sum())
        last  = int(df_monthly[f"누적_{w}"].iloc[-1]) if len(df_monthly) else 0
        if s_in - s_out != last:
            bad.append((w, s_in, s_out, last, s_in - s_out))
    return bad
```

**근거 메모**

* `pivot_table(..., fill_value=0)`와 피벗/언스택의 `fill_value`는 공식 문서에 명시. ([pandas.pydata.org][1])
* `to_datetime(errors="coerce")`는 변환 불가를 NaT로 보낸다고 명시. ([pandas.pydata.org][2])
* `tz_convert/tz_localize`로 타임존 변환/부여. ([pandas.pydata.org][3])
* `melt`로 가로→세로 변환. ([pandas.pydata.org][4])
* 누적합 `cumsum`은 표준. ([pandas.pydata.org][5])

---

# 2) `report_generator.py` 패치 (정확한 위치)

### (A) import 추가 — 파일 상단 import 블록에 삽입

```python
# report_generator.py (상단)
from core.flow_ledger_v2 import (
    build_flow_ledger,
    monthly_inout_table as fl_monthly_inout_table,
    sanity_report as fl_sanity_report,
    _warehouse_labels,
)
```

### (B) 생성부 교체 — “창고_월별_입출고” 시트를 만들던 함수 내부

기존에 소스별 집계 또는 이전 v1 레저를 쓰던 **월별 표 구성 파트 전체**를 아래로 교체:

```python
# (예) def create_warehouse_monthly_sheet_enhanced(self, stats): 내부
# 1) 마스터 프레임 확보 (프로젝트 구조에 맞춰 조정)
master_df = stats.get("master") or stats.get("case_master") or getattr(self, "combined_data", None)
if master_df is None:
    master_df = pd.DataFrame()

# 2) 전이 레저 생성
ledger_df, edges_df = build_flow_ledger(master_df)

# 3) 월별 입/출고/누적 표 생성
warehouses = _warehouse_labels()
df_monthly = fl_monthly_inout_table(ledger_df, warehouses)

# 4) 필수 검산 — 어긋나면 즉시 실패로 올림
bad = fl_sanity_report(df_monthly)
if bad:
    # 첫 5개만 메시지에 포함
    raise ValueError(f"[FlowLedger mismatch] {bad[:5]}")

# 5) (기존) 엑셀 시트/리포트 출력을 위한 리턴 or 후속 결합
return df_monthly
```

> 위 ②–④가 **핵심 교체 지점**이에요. 이 줄들만 정확히 바꾸면 “입고가 0인데 누적만 증가” 같은 현상은 더 이상 발생하지 않습니다(전이/동일시각 병합/타임존 월버킷이 선반영이니까).

---

# 3) 실행 전/후 체크(빠른 스모크)

```python
# 실행 직후
bad = fl_sanity_report(df_monthly)
assert not bad, f"불일치: {bad}"

# (선택) DSV Indoor만 확인
w = "DSV Indoor"
assert df_monthly[f"입고_{w}"].sum() - df_monthly[f"출고_{w}"].sum() == df_monthly[f"누적_{w}"].iloc[-1]
```

---

# 4) 자주 틀리는 포인트(2줄 요약)

* **월 버킷은 집계 전에** 타임존을 두바이로 **통일**하고 자르기(월 경계 밀림 방지). ([pandas.pydata.org][3])
* 동일시각 중복은 **합산(sum)**, 서로 다른 창고 동시기록은 **전이 체인**으로 해석.

---

필요하면 “동일시각 합산을 `sum↔max` 토글”로 바꾸는 스위치를 넣어줄 수 있어. 먼저 이 패치로 돌리고, 결과 스냅샷(특히 DSV Indoor) 한 번만 던져줘. 거기서 더 미세한 규칙(예: 특정 창고 우선순위)까지 맞춤 튜닝 들어가자.

[1]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html?utm_source=chatgpt.com "pandas.pivot_table — pandas 2.3.3 documentation - PyData |"
[2]: https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html?utm_source=chatgpt.com "pandas.to_datetime — pandas 2.3.3 documentation - PyData |"
[3]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.tz_convert.html?utm_source=chatgpt.com "pandas.Series.dt.tz_convert — pandas 2.3.3 documentation"
[4]: https://pandas.pydata.org/docs/reference/api/pandas.melt.html?utm_source=chatgpt.com "pandas.melt — pandas 2.3.3 documentation - PyData |"
[5]: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html?utm_source=chatgpt.com "pandas.DataFrame.cumsum — pandas 2.3.3 documentation"
